{
  "hash": "0e3ad39fcc2a8c1509f1ab065cae9a26",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Preprocessing\"\nformat: html\nexecute: \n  cache: true\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(\"tidyverse\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(\"lme4\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(\"lmerTest\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'lmerTest'\n\nThe following object is masked from 'package:lme4':\n\n    lmer\n\nThe following object is masked from 'package:stats':\n\n    step\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(\"plotrix\")\nlibrary(\"lattice\")\nsource('data/custom-theme.R')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n## Import data\ndata <- read_csv(\"data/data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 32112 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Condition, yesButton, Source, Prefix\ndbl (4): Participant, RT, ACC, Item.no\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Preprocessing Function according to preregistration https://osf.io/kz26a\n\n## Participants rejecting 10% of the grammatical items will be excluded from analysis. \n## We will first remove responses shorter than 200 ms. Further outlier removal will be performed following Baayen and Millin (2010), by fitting a simple mixed model with only random effects and \n## excluding all data points with residuals exceeding 2.5 SD.\n\npreprocessing_fn_prereg <- function(var1){\n  data <- var1\n  data_Gramm <- data %>% filter(Condition ==\"Gramm\")\n  data_critical <- data %>% filter(Condition !=\"Filler\")\n\n## Filler Accuracy\n\n  data_ACC_Gramm <- data_Gramm %>%\n    group_by(Participant)%>%\n    summarise(ACC=mean(ACC)*100)\n\n  Fill_rej <- n_distinct(exc_participant <- data_ACC_Gramm %>% filter(ACC < 90))\n  Fill_acc <- n_distinct(inc_participant <- data_ACC_Gramm %>% filter(ACC >= 90))\n\n  Data <-data_critical[!data_critical$Participant %in% exc_participant$Participant,]\n\n## Minimal Trimming\n\n  min_trim_rm <- filter(Data, RT < 200)\n  Data_min_trim<- filter(Data, RT >= 200)\n  \n  return(Data_min_trim)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Preprocessing Function according to PostHoc analysis\n\n## Participants with less than 75% accuracy of the filler items will be excluded from analysis. \n## We will first remove responses shorter than 200 ms. Further outlier removal will be performed following Baayen and Millin (2010), by fitting a simple mixed model with only random effects and \n## excluding all data points with residuals exceeding 2.5 SD.\n\npreprocessing_fn <- function(var1){\n  data <- var1\n  data_filler <- data %>% filter(Condition ==\"Filler\")\n  data_critical <- data %>% filter(Condition !=\"Filler\")\n\n## Filler Accuracy\n\n  data_ACC_filler <- data_filler %>%\n    group_by(Participant)%>%\n    summarise(ACC=mean(ACC)*100)\n\n  Fill_rej <- n_distinct(exc_participant <- data_ACC_filler %>% filter(ACC <75))\n  Fill_acc <- n_distinct(inc_participant <- data_ACC_filler %>% filter(ACC >=75))\n\n  Data <-data_critical[!data_critical$Participant %in% exc_participant$Participant,]\n\n## Minimal Trimming\n\n  min_trim_rm <- filter(Data, RT < 200)\n  Data_min_trim<- filter(Data, RT >= 200)\n  \n  return(Data_min_trim)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n##########################\n###   2.5 SD analysis  ###\n##########################\nSD_exclusion <- function(DATA){\n  \n  exceeds <- list()\n  \n  datad <- DATA %>%\n    group_by(Participant, Condition) %>%\n    summarise(Mean=mean(RT), SD=sd(RT), UpperLimit=SD*2.5+Mean)\n  datac <- DATA %>% \n    group_by(Condition) %>% \n    summarise(Mean=mean(RT), SD=sd(RT), UpperLimit=SD*2.5+Mean)\n  \n  #grammatical condition\n  data_rt_gramm <- datad %>% filter(Condition==\"Gramm\")\n  MaxGramm <-max(data_rt_gramm$Mean)\n  UpperLimitGramm <- datac[datac$Condition==\"Gramm\",]$UpperLimit\n  \n  data_rt_cat<-datad%>%filter(Condition==\"CatViol\") #CAtViol condition\n  MaxCat <-max(data_rt_cat$Mean)\n  UpperLimitCat <- datac[datac$Condition==\"CatViol\",]$UpperLimit\n  \n  data_rt_sem<-datad%>%filter(Condition==\"SemViol\") #SemViol condition\n  MaxSem <-max(data_rt_sem$Mean)\n  UpperLimitSem <- datac[datac$Condition==\"SemViol\",]$UpperLimit\n  \n  if (MaxGramm > UpperLimitGramm){\n    print (\"Gramm Problem\")\n    exceeds <- append(exceeds, \"Gramm\")\n  } else if (MaxCat> UpperLimitCat){\n    print (\"CatViol Problem\")\n    exceeds <- append(exceeds, \"CatViol\")\n  } else if  (MaxSem > UpperLimitSem){\n    print (\"SemViol Problem\")\n    exceeds <- append(exceeds, \"SemViol\")\n  } else {\n    print (\"No Problemo\")\n    exceeds <- append(exceeds, \"All Good\")\n  }  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Examine and remove some outliers based on Baayen and Milin (2010)\n\noutliers_removal <- function(DATA){\n  print (\"Examine and remove some outliers based on Baayen and Milin (2010)\")\n  \n  qqmath(~RT | Participant, data = DATA)\n  \n  f = function(dfr)\n    return(shapiro.test(dfr$RT)$p.value)\n  \n  p = as.vector(by(DATA, DATA$Participant, f))\n  names(p) = levels(DATA$Participant)\n  names(p[p < 0.05])\n  \n  print(\"Revised RT's .................. \")\n  paste(\"Gramm RT: \",mean(DATA[DATA$Condition==\"Gramm\",]$RT))\n  paste(\"CatViol RT: \",mean(DATA[DATA$Condition==\"CatViol\",]$RT))\n  paste(\"SemViol RT: \",mean(DATA[DATA$Condition==\"SemViol\",]$RT))\n  \n  ###########################################\n  ### Model criticism by Baayen and Milin ###\n  ###########################################\n  print(\"Model criticism by Baayen and Milin\")\n  \n  BanFullModel <- lmer(RT ~ (1|Participant) + (1|Item), data = DATA, REML = F)\n  cor(fitted(BanFullModel), DATA$RT)^2\n  \n  BanFullModel_Res = DATA[abs(scale(resid(BanFullModel))) < 2.5,]\n  BanFullModel_2 <- lmer(RT ~ (1|Participant) + (1|Item), data = BanFullModel_Res, REML = F)\n  cor(fitted(BanFullModel_2), BanFullModel_Res$RT)^2\n  \n  ###########################################\n  \n  qqmath(~RT | Participant, data = BanFullModel_Res)\n  \n  f = function(dfr)\n    return(shapiro.test(dfr$RT)$p.value)\n  \n  p = as.vector(by(BanFullModel_Res, BanFullModel_Res$Participant, f))\n  names(p) = levels(BanFullModel_Res$Participant)\n  names(p[p < 0.05])\n  \n  #############################\n  BanFullModel_Res_Correct <- BanFullModel_Res %>% filter(ACC==\"1\")\n  #############################\n  Gramm <- mean(BanFullModel_Res_Correct[BanFullModel_Res_Correct$Condition==\"Gramm\",]$RT)\n  CatViol <- mean(BanFullModel_Res_Correct[BanFullModel_Res_Correct$Condition==\"CatViol\",]$RT)\n  SemViol <- mean(BanFullModel_Res_Correct[BanFullModel_Res_Correct$Condition==\"SemViol\",]$RT)\n  \n  paste(\"Gramm RT: \", Gramm)\n  paste(\"Catviol RT: \", CatViol)\n  paste(\"Semviol RT: \", SemViol)\n  \n  sprintf( \"Gramm vs. CatViol: %f - %f\", Gramm, CatViol )\n  sprintf( \"Gramm vs. CatViol :  %f - %f\", Gramm, SemViol )\n  sprintf( \"Gramm vs. CatViol :  %f - %f\", SemViol, CatViol )\n  \n  return(BanFullModel_Res_Correct)\n}\n```\n:::\n\n\n## Preregistered Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nBAN_Data_prereg <- preprocessing_fn_prereg(data)\nprereg_data_SD <- SD_exclusion(BAN_Data_prereg)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'Participant'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"No Problemo\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nprint(prereg_data_SD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"All Good\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n# Examine and remove some outliers based on Baayen and Milin (2010)\n\nDATA_prereg <- BAN_Data_prereg %>% \n  mutate(\n    Participant = as.factor(Participant),\n    Condition = as.factor(Condition),\n    Item = as.factor(Item.no),\n    Prefix = as.factor(Prefix)\n  )\n\nBAN_Data_PR <- outliers_removal(DATA_prereg)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Examine and remove some outliers based on Baayen and Milin (2010)\"\n[1] \"Revised RT's .................. \"\n[1] \"Model criticism by Baayen and Milin\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nBAN_Data_PR <- BAN_Data_PR %>% select(!(Item))\n\n\nwrite_csv(BAN_Data_prereg, \"data/BAN_ACCData_prereg_Trimmed.csv\")\nwrite_csv(BAN_Data_PR, \"data/BAN_RTData_prereg_Resid-Trimmed.csv\")\n```\n:::\n\n\n## Exploratory Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n#| label: setup\nBAN_Data <- preprocessing_fn(data)\ndata_SD <- SD_exclusion(BAN_Data)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n`summarise()` has grouped output by 'Participant'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"No Problemo\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| label: setup\nprint(data_SD)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"All Good\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| label: setup\n# Examine and remove some outliers based on Baayen and Milin (2010)\n\nDATA <- BAN_Data %>% \n  mutate(\n    Participant = as.factor(Participant),\n    Condition = as.factor(Condition),\n    Item = as.factor(Item.no),\n    Prefix = as.factor(Prefix)\n  )\n\nDATA <- outliers_removal(DATA)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Examine and remove some outliers based on Baayen and Milin (2010)\"\n[1] \"Revised RT's .................. \"\n[1] \"Model criticism by Baayen and Milin\"\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\n#| label: setup\nDATA <- DATA %>% select(!(Item))\nwrite_csv(BAN_Data, \"data/BAN_ACCData_Trimmed.csv\")\nwrite_csv(DATA, \"data/BAN_RTData_Resid-Trimmed.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}